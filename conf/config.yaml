
####################################################################
# hydra configs
####################################################################
hydra:
  run:
    dir: out/${model.name}/${experiment.name}/${now:%Y%m%d_%H%M%S}

  sweep:
    dir: out/multirun/${experiment.name}
    subdir: ${now:%Y%m%d_%H%M%S}_${hydra.job.override_dirname}_${hydra.job.num}

####################################################################
# set configs
####################################################################
defaults:
#  - model_conf@_global_: cash_first2
#  - model_conf@_global_: mcd_first
#  - data_conf@_global_: global_asset
#  - exp_conf@experiment: pretrained_mcd
  - model_conf@_global_: cash_first2
  - data_conf@_global_: emdm
  - exp_conf@experiment: h
  - exp_conf/data_exp_conf@experiment: ${defaults.1.data_conf}_${defaults.2.exp_conf}
#  - exp_conf/data_exp_conf@experiment: ${defaults.1.data_conf}_m
  - trainer_conf@_global_: stage2_losswgt_pf
#  - trainer_conf@_global_: mcd_first
#  - trainer_conf@_global_: ${defaults.1.data_conf}_${defaults.2.exp_conf}_s1_load

####################################################################
# data configs (default)
####################################################################
data:
  update: 20210228

  batch_size: 512
  sampling_freq: 20
  k_days: 20
  label_days: 20
  strategy_days: 250
  eval_rate: 0.6

  retrain_days: 240
  test_days: 5000  # test days
  init_train_len: 500
  train_data_len: 2000
  normalizing_window: 500  # norm windows for macro data_conf
  use_accum_data: True  # [sampler] 데이터 누적할지 말지

  random_guide_weight: 0.1
  random_flip: 0.1  # flip sign
  random_label: 0.1  # random sample from dist.

####################################################################
# model configs (default)
####################################################################
model:
  name: default

  d_model: 128
  dropout_r: 0.3

  mcdropout:
    in_dim: ${model.d_model}
    out_dim: "(eval) <replace>experiment.adjusted_num_assets</replace>"
    hidden_dim:
      - 128
      - 128
    dropout_r: ${model.dropout_r}
    mc_samples: 1000

  allocator:
    # num_assets: {wgt, mean, std} + d_model: {x_emb, attn output}
    in_dim: "(eval) <replace>experiment.adjusted_num_assets</replace> * 3 + ${model.d_model} * 2"
    out_dim: "(eval) <replace>experiment.adjusted_num_assets</replace> * 2"
    hidden_dim:
      - 128
      - 64

  ## attention
  attention:
    d_model: ${model.d_model}
    n_heads: 8
    d_k: "(eval) ${model.attention.d_model} // ${model.attention.n_heads}"
    d_v: "(eval) ${model.attention.d_model} // ${model.attention.n_heads}"
    d_ff: 128


####################################################################
# trainer configs (default)
####################################################################
trainer:
  stage1:
    use: True
    monitor: 'val_loss'
    patience: 20
    lr: 0.01
    loss_wgt:
      'y_pf': 0.0
      'mdd_pf': 0.0
      'logy': 0.0
      'wgt_guide': 0.5
      'cost': 10.0

  stage2:
    use: True
    monitor: 'val_loss'
    patience: 50
    warmup: 20
    lr: ${experiment.lr}
    loss_wgt:
      'y_pf': 1
      'mdd_pf': 1.0
      'logy': 1.0
      'wgt_guide': 0.02
      'cost': 1.0

  gpus: 1
  check_val_every_n_epoch: 1  # 20
  gradient_clip_val: 1.
  max_epochs: 1000
  auto_scale_batch_size:   # None | power | binsearch

  loss_threshold:   # -1

####################################################################
# experiment configs (default)
####################################################################
experiment:
  ii: 3900
  seed: 1000

  # default
  base_i0: 2000
  cost_rate: 0.003
  lr: 0.05
  mdd_cp: 0.05

  wgt_loss_alpha: 10 # loss['wgt_guide'] 계산할 때 exponential하게 증가 하게끔 해주는 계수
  wgt_loss_alpha2: 100 # loss['wgt_guide'] 계산할 때 min/max range를 벗어났을때의 패널티 계수

  use_guide_wgt_as_prev_x: False  # models / forward_with_loss
  plot_freq: 10

  # data related
  excluded_asset_idx:

  num_excluded_assets: "(eval) 0 if ${experiment.excluded_asset_idx} is None else len(${experiment.excluded_asset_idx})"
  adjusted_num_assets: "(eval) ${data.num_assets} - <replace>experiment.num_excluded_assets</replace>"
  cash_idx: "(eval) ${data.cash_idx} - len([i for i in (${experiment.excluded_asset_idx} if ${experiment.excluded_asset_idx} is not None else []) if i <= ${data.cash_idx}])"
#  cash_idx: ${data.cash_idx}

#  outpath: ./out/${model.name}/${experiment.name}/{now:%Y%m%s_%H%M%S}
  outpath: .    # working directory가 알아서 바뀜... hydra.utils.to_absolute_path or utils.get_original_cwd()

logger:
  path_name: tb_logs
  name: my_model

